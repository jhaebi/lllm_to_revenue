{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c7c907-9ea3-4e98-9ba0-49f083366294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from ipywidgets import Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "\n",
    "# Define constants\n",
    "CONTEXT = \"context\"\n",
    "HUMAN_INPUT = \"human_input\"\n",
    "CHAT_HISTORY_INDICATOR = \"chat_history_indicator\"\n",
    "OPENAI_CHAT_MODEL = \"gpt-3.5-turbo\"\n",
    "TOP_DOC_NUM = 3\n",
    "SUPPORT_DOC_PATH = None\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "# Use the home directory as the base path for your writable directory\n",
    "home_directory = os.environ['HOME']\n",
    "# Specify a subdirectory within the home directory\n",
    "SUPPORT_DOC_FOLDER_PATH = os.path.join(home_directory, 'support_docs')\n",
    "# SUPPORT_DOC_FOLDER_PATH = '../support_docs'\n",
    "\n",
    "script_chain = None\n",
    "\n",
    "def return_generate_ai_script(template_text: str, user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate an AI script and append it to a template.\n",
    "\n",
    "    Args:\n",
    "        template_text (str): Template for LLM model.\n",
    "        message_text (str): User Question.\n",
    "        retrieved_docs (list): List of retrieved documents.\n",
    "\n",
    "    Returns:\n",
    "        str: AI output string.\n",
    "    \"\"\"\n",
    "    \n",
    "    global script_chain\n",
    "\n",
    "    # Load an embedding model from OpenAI\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    all_docs = list(process_doc_files(SUPPORT_DOC_FOLDER_PATH).values())\n",
    "\n",
    "    # Transform my docs into vectors and store that into a database (chroma) for managing and querying the embeddings\n",
    "    docsearch = Chroma.from_texts(all_docs, embeddings)\n",
    "    \n",
    "    # Use cosign similarity to perform the search for documents similar to the user query\n",
    "    similar_docs = docsearch.similarity_search(user_query, k = 1)    \n",
    "    \n",
    "    # Initialize script_chain if it doesn't exist\n",
    "    if script_chain is None:\n",
    "            \n",
    "        # Input for the prompt\n",
    "        prompt = PromptTemplate(input_variables=[CHAT_HISTORY_INDICATOR, HUMAN_INPUT, CONTEXT], template=template_text)\n",
    "    \n",
    "        # Input for the Memory class\n",
    "        memory = ConversationBufferMemory(memory_key=CHAT_HISTORY_INDICATOR, input_key = HUMAN_INPUT )\n",
    "\n",
    "        # Load LLM model\n",
    "        llm = ChatOpenAI(model_name=OPENAI_CHAT_MODEL, temperature=0)        \n",
    "\n",
    "        # Feed LLM model, memory object, and prompt to the Q and A chain function\n",
    "        script_chain = load_qa_chain(llm = llm, chain_type=\"stuff\", memory= memory, prompt=prompt)\n",
    "        \n",
    "    gen_ai_output = script_chain({\"input_documents\": similar_docs, HUMAN_INPUT: user_query}, return_only_outputs=True)\n",
    "\n",
    "    print('Chain memory: ', script_chain.memory.buffer)\n",
    "\n",
    "    return gen_ai_output['output_text']\n",
    "\n",
    "\n",
    "def process_doc_files(SUPPORT_DOC_FOLDER_PATH) -> dict:\n",
    "    \"\"\"\n",
    "    Process text files in a folder and return a dictionary with file names as keys and content as values.\n",
    "\n",
    "    :param folder_path: The path to the folder containing the text files.\n",
    "    :return: A dictionary with file names as keys and content as values.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the results\n",
    "    doc_dict = {}\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(SUPPORT_DOC_FOLDER_PATH):\n",
    "        return doc_dict  # Return an empty dictionary if the folder does not exist\n",
    "\n",
    "    # List all files in the folder\n",
    "    file_list = os.listdir(SUPPORT_DOC_FOLDER_PATH)\n",
    "\n",
    "    # Iterate through the files\n",
    "    for filename in file_list:\n",
    "        # Check if the file has a .txt extension\n",
    "        if filename.endswith(\".txt\"):\n",
    "            # Create the full path to the file\n",
    "            file_path = os.path.join(SUPPORT_DOC_FOLDER_PATH, filename)\n",
    "\n",
    "            # Open the file and read its content\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Store the content in the dictionary with the filename as the key\n",
    "            doc_dict[filename] = file_content\n",
    "\n",
    "    return doc_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aead68-55b9-42b9-b1c1-06fc93c29cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def download_s3_folder(bucket_name, folder_name, local_directory):\n",
    "        \n",
    "#     session = boto3.Session(\n",
    "#         aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#         aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "#         region_name=AWS_DEFAULT_REGION\n",
    "#     )\n",
    "    \n",
    "#     s3 = session.resource('s3')\n",
    "#     my_bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "#     # Ensure the local directory exists\n",
    "#     if not os.path.exists(local_directory):\n",
    "#         os.makedirs(local_directory)\n",
    "\n",
    "#     for s3_object in my_bucket.objects.filter(Prefix=folder_name):\n",
    "#         local_file_path = os.path.join(local_directory, os.path.basename(s3_object.key))\n",
    "#         local_file_path = local_file_path.rstrip('/')  # Remove trailing slashes\n",
    "#         print(s3_object.key, local_file_path)        \n",
    "#         try:\n",
    "#             my_bucket.download_file(s3_object.key, local_file_path)\n",
    "#         except Exception as e:\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191670e8-38b8-4da8-8b83-f87cd1718d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c88bc1-2508-45bd-99f6-141b9ea93799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c57cf6-a1aa-4f6d-93ad-095558146b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
