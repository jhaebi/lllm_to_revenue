{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa604e-fdd8-40b3-a807-489cbb4a4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from ipywidgets import Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8de7f-5665-422a-85af-a5a89c706cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5524d-0573-4e30-a6de-54f68e4e0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_HISTORY_INDICATOR = 'chat_history_indicator'\n",
    "HUMAN_INPUT = 'human_input'\n",
    "CONTEXT = 'context'\n",
    "SUPPORT_DOC_FOLDER_PATH = 'support_docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de869ae-0157-4701-97ab-c8f1e2386001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc_files(SUPPORT_DOC_FOLDER_PATH) -> dict:\n",
    "    \"\"\"\n",
    "    Process text files in a folder and return a dictionary with file names as keys and content as values.\n",
    "\n",
    "    :param folder_path: The path to the folder containing the text files.\n",
    "    :return: A dictionary with file names as keys and content as values.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the results\n",
    "    doc_dict = {}\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(SUPPORT_DOC_FOLDER_PATH):\n",
    "        return doc_dict  # Return an empty dictionary if the folder does not exist\n",
    "\n",
    "    # List all files in the folder\n",
    "    file_list = os.listdir(SUPPORT_DOC_FOLDER_PATH)\n",
    "\n",
    "    # Iterate through the files\n",
    "    for filename in file_list:\n",
    "        # Check if the file has a .txt extension\n",
    "        if filename.endswith(\".txt\"):\n",
    "            # Create the full path to the file\n",
    "            file_path = os.path.join(SUPPORT_DOC_FOLDER_PATH, filename)\n",
    "\n",
    "            # Open the file and read its content\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Store the content in the dictionary with the filename as the key\n",
    "            doc_dict[filename] = file_content\n",
    "\n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b21353-1915-4656-badf-3339c478e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_chain = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed9223-227b-44de-b285-d05e1b6ec10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backend_code(template_text: str, user_query: str  ):\n",
    "\n",
    "    global script_chain\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    all_docs = list(process_doc_files(SUPPORT_DOC_FOLDER_PATH).values())\n",
    "    docsearch = Chroma.from_texts(all_docs, embeddings)\n",
    "    \n",
    "    similar_docs = docsearch.similarity_search(user_query, k = 1)\n",
    "\n",
    "    # initialize script chain if it doesn't exist\n",
    "    if script_chain is None:\n",
    "        llm = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature = 0)\n",
    "        prompt = PromptTemplate(input_variables = [CHAT_HISTORY_INDICATOR,HUMAN_INPUT, CONTEXT ], template= template_text )\n",
    "        memory = ConversationBufferMemory(memory_key = CHAT_HISTORY_INDICATOR, input_key = HUMAN_INPUT)\n",
    "        \n",
    "        script_chain = load_qa_chain(llm = llm, chain_type = 'stuff', memory = memory, prompt = prompt)\n",
    "\n",
    "    gen_ai_output = script_chain({\"input_documents\":similar_docs, HUMAN_INPUT: user_query}, return_only_outputs = True)\n",
    "\n",
    "    print(script_chain.memory.buffer)\n",
    "\n",
    "    return gen_ai_output['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755d9ec-8fb1-464f-97d0-48ae7082b913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46201a0b-d895-49c4-afa6-355edb8d8182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (myenv310)",
   "language": "python",
   "name": "myenv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
