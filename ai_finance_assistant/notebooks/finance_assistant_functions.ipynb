{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "351da25b-ce48-49ae-af97-a0874c6960b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from ipywidgets import Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.tools import YouTubeSearchTool\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "import ast \n",
    "\n",
    "# Define constants\n",
    "CONTEXT = \"context\"\n",
    "HUMAN_INPUT = \"human_input\"\n",
    "CHAT_HISTORY_INDICATOR = \"chat_history_indicator\"\n",
    "OPENAI_CHAT_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "# OPENAI_API_KEY = os.environ.get(OPENAIAPIKEY)\n",
    "\n",
    "\n",
    "script_chain = None\n",
    "\n",
    "def return_generate_ai_script(template_text: str, user_query: str, all_docs: list) -> str:\n",
    "    \"\"\"\n",
    "    Generate an AI script and append it to a template.\n",
    "\n",
    "    Args:\n",
    "        template_text (str): Template for LLM model.\n",
    "        message_text (str): User Question.\n",
    "        retrieved_docs (list): List of retrieved documents.\n",
    "\n",
    "    Returns:\n",
    "        str: AI output string.\n",
    "    \"\"\"\n",
    "    global script_chain\n",
    "\n",
    "    # Load an embedding model from OpenAI\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # Transform my docs into vectors and store that into a database (chroma) for managing and querying the embeddings\n",
    "    docsearch = Chroma.from_texts(all_docs, embeddings, metadatas=[{\"source\": i} for i in range(len(all_docs))])\n",
    "\n",
    "    # Use cosign similarity to perform the search for documents similar to the user query\n",
    "    similar_docs = docsearch.similarity_search(user_query)\n",
    "    \n",
    "    # Initialize script_chain if it doesn't exist\n",
    "    if script_chain is None:\n",
    "             \n",
    "        # Input for the prompt\n",
    "        prompt = PromptTemplate(input_variables=[CHAT_HISTORY_INDICATOR, HUMAN_INPUT, CONTEXT], template=template_text)\n",
    "    \n",
    "        # Input for the Memory class\n",
    "        memory = ConversationBufferMemory(memory_key=CHAT_HISTORY_INDICATOR, input_key = HUMAN_INPUT )\n",
    "\n",
    "        # Load LLM model\n",
    "        llm = ChatOpenAI(model_name=OPENAI_CHAT_MODEL, temperature=0)        \n",
    "\n",
    "        # Feed LLM model, memory object, and prompt to the Q and A chain library\n",
    "        script_chain = load_qa_chain(llm = llm, chain_type=\"stuff\", memory= memory, prompt=prompt)\n",
    "        \n",
    "    gen_ai_output = script_chain({\"input_documents\": similar_docs, HUMAN_INPUT: user_query}, return_only_outputs=True)\n",
    "\n",
    "    print('Chain memory: ', script_chain.memory.buffer)\n",
    "\n",
    "    return gen_ai_output['output_text']\n",
    "\n",
    "\n",
    "def return_youtube_docs(query, num_of_docs):\n",
    "    tool = YouTubeSearchTool()\n",
    "    search_result = tool.run(query + ', '+ str(num_of_docs))\n",
    "    result_list = ast.literal_eval(search_result)\n",
    "\n",
    "    all_docs = []\n",
    "    \n",
    "    for link in result_list:\n",
    "    \n",
    "        loader = YoutubeLoader.from_youtube_url(\n",
    "            'https://www.youtube.com' + link, add_video_info=True\n",
    "        )\n",
    "    \n",
    "        doc = loader.load()\n",
    "        all_docs.append(doc[0].page_content)\n",
    "\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66b8aa-b3c0-4892-b95c-171d5d63166f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04444358-189b-47d9-8430-a48d8dbc3bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa10989-153a-4151-8203-53687f6e52a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6b679-38a7-4da8-be74-e9451dec7f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5cecbc-a677-410f-a383-3224456d7f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a70fb-4ac8-4869-98b3-8fbdaf7ba810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f4c8a-9554-4a13-b5df-d336b5e36b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (myenv310)",
   "language": "python",
   "name": "myenv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
